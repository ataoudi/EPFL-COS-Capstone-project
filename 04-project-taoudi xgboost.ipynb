{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> XGboost model </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import *\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('forkserver')\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32234, 2325) (8059, 2325)\n"
     ]
    }
   ],
   "source": [
    "## load data from data.npz\n",
    "def load_data():\n",
    "    X_train = pd.read_pickle(\"./X_train.pkl\")\n",
    "    X_test  = pd.read_pickle(\"./X_test.pkl\")\n",
    "    with np.load('data.npz', allow_pickle=True) as npz_file:\n",
    "        y_train_cla=pd.Series(npz_file['y_train_cla'] , name='book_rating_class')\n",
    "        y_train_reg=pd.Series(npz_file['y_train_reg'] , name='book_rating_count_log')\n",
    "        authors_df_train=pd.DataFrame(npz_file['authors_df_train'] , columns=npz_file['authors_to_keep'])\n",
    "        genres_df_train=pd.DataFrame(npz_file['genres_df_train'] , columns=npz_file['genres_to_keep'])\n",
    "        format_df_train=pd.DataFrame(npz_file['format_df_train'] , columns=npz_file['formats_to_keep'])\n",
    "        title_df_train=pd.DataFrame(npz_file['title_df_train'] , columns=npz_file['title_columns'])\n",
    "        desc_df_train=pd.DataFrame(npz_file['desc_df_train'] , columns=npz_file['desc_columns'])\n",
    "        image_df_train=pd.DataFrame(npz_file['image_df_train'] , columns=npz_file['image_columns'])\n",
    "        y_test_cla=pd.Series(npz_file['y_test_cla'] , name='book_rating_class')\n",
    "        y_test_reg=pd.Series(npz_file['y_test_reg'] , name='book_rating_count_log')\n",
    "        authors_df_test=pd.DataFrame(npz_file['authors_df_test'] , columns=npz_file['authors_to_keep'])\n",
    "        genres_df_test=pd.DataFrame(npz_file['genres_df_test'] , columns=npz_file['genres_to_keep'])\n",
    "        format_df_test=pd.DataFrame(npz_file['format_df_test'] , columns=npz_file['formats_to_keep'])\n",
    "        title_df_test=pd.DataFrame(npz_file['title_df_test'] , columns=npz_file['title_columns'])\n",
    "        desc_df_test=pd.DataFrame(npz_file['desc_df_test'] , columns=npz_file['desc_columns'])\n",
    "        image_df_test=pd.DataFrame(npz_file['image_df_test'] , columns=npz_file['image_columns']) \n",
    "        authors_to_keep=npz_file['authors_to_keep']\n",
    "        genres_to_keep=npz_file['genres_to_keep']\n",
    "        formats_to_keep=npz_file['formats_to_keep']\n",
    "        title_columns=npz_file['title_columns']\n",
    "        desc_columns=npz_file['desc_columns']\n",
    "        image_columns=npz_file['image_columns']\n",
    "    return X_train,y_train_cla,y_train_reg, authors_df_train, genres_df_train, format_df_train, title_df_train, desc_df_train, image_df_train, X_test,y_test_cla,y_test_reg, authors_df_test, genres_df_test, format_df_test, title_df_test, desc_df_test, image_df_test, authors_to_keep, genres_to_keep, formats_to_keep, title_columns,desc_columns,image_columns\n",
    "    #return X_train,y_train_cla,y_train_reg, authors_df_train, genres_df_train, format_df_train, title_df_train, desc_df_train, X_test,y_test_cla,y_test_reg, authors_df_test, genres_df_test, format_df_test, title_df_test, desc_df_test, authors_to_keep, genres_to_keep, formats_to_keep, title_columns,desc_columns,image_columns\n",
    "X_train_base,y_train_cla,y_train_reg, authors_df_train, genres_df_train, format_df_train, title_df_train, desc_df_train, image_df_train, X_test_base,y_test_cla,y_test_reg, authors_df_test, genres_df_test, format_df_test, title_df_test, desc_df_test, image_df_test, authors_to_keep, genres_to_keep, formats_to_keep, title_columns,desc_columns,image_columns = load_data()\n",
    "#X_train_base,y_train_cla,y_train_reg, authors_df_train, genres_df_train, format_df_train, title_df_train, desc_df_train, X_test_base,y_test_cla,y_test_reg, authors_df_test, genres_df_test, format_df_test, title_df_test, desc_df_test, authors_to_keep, genres_to_keep, formats_to_keep, title_columns,desc_columns,image_columns = load_data()\n",
    "X_train = pd.concat((X_train_base.book_pages_log,authors_df_train, genres_df_train, format_df_train, title_df_train, desc_df_train), axis=1)\n",
    "X_test = pd.concat((X_test_base.book_pages_log,authors_df_test, genres_df_test, format_df_test, title_df_test, desc_df_test), axis=1)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our xgboost model with a grid of parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cla_1h = LabelBinarizer().fit_transform(y_train_cla.values.reshape(-1, 1))\n",
    "y_test_cla_1h = LabelBinarizer().fit_transform(y_test_cla.values.reshape(-1, 1))\n",
    "#dtrain = xgb.DMatrix(data=X_train.head(100), label=y_train_cla.head(100))\n",
    "#dtest = xgb.DMatrix(data=X_test.head(100))\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train_cla)\n",
    "dtest = xgb.DMatrix(data=X_test)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': np.array([0.01,0.001]),\n",
    "    'subsample': np.array([0.7,0.8,0.9]),\n",
    "    'max_depth': np.array([10,11,12,13,14,15,16,17]),\n",
    "    'lambda': np.array([1]),\n",
    "    'gamma': np.array([0]),\n",
    "    'nthread': [16],\n",
    "    'objective': ['multi:softprob'], \n",
    "    'num_class': [4]\n",
    "}\n",
    "def fit_xgb(params, y_train_cla, y_train_cla_1h, y_test_cla, y_test_cla_1h):\n",
    "    model = xgb.train(params, dtrain) \n",
    "    pred = model.predict(dtest)\n",
    "    tr_pred = model.predict(dtrain)\n",
    "    s1 = roc_auc_score(y_train_cla_1h, tr_pred)\n",
    "    s2 = accuracy_score(y_train_cla, np.argmax(tr_pred,axis=1))\n",
    "    #print ('train : auc score :%s, accuracy score :%s'%(s1,s2))\n",
    "    s1_t = roc_auc_score(y_test_cla_1h, pred)\n",
    "    s2_t = accuracy_score(y_test_cla, np.argmax(pred,axis=1))\n",
    "    #print ('test : auc score :%s, accuracy score :%s'%(s1_t,s2_t))\n",
    "    return (params, s2, s1, s2_t, s1_t), pred\n",
    "def grid_xgb(params):\n",
    "    results =[]\n",
    "    preds=[]\n",
    "    for param in ParameterGrid(params):\n",
    "        #res, pred = fit_xgb(param, y_train_cla.head(100), y_train_cla_1h[:100], y_test_cla.head(100), y_test_cla_1h[:100])\n",
    "        res, pred =  fit_xgb(param, y_train_cla, y_train_cla_1h, y_test_cla, y_test_cla_1h)\n",
    "        results += [res]\n",
    "        preds += [pred]\n",
    "    return results, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, preds =  grid_xgb(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows results for each hyperparameter grid combination :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.780821</td>\n",
       "      <td>0.935099</td>\n",
       "      <td>0.428465</td>\n",
       "      <td>0.689275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.785692</td>\n",
       "      <td>0.937528</td>\n",
       "      <td>0.424122</td>\n",
       "      <td>0.689317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.781194</td>\n",
       "      <td>0.935619</td>\n",
       "      <td>0.424618</td>\n",
       "      <td>0.691006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.839517</td>\n",
       "      <td>0.960353</td>\n",
       "      <td>0.428465</td>\n",
       "      <td>0.690851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.846032</td>\n",
       "      <td>0.963506</td>\n",
       "      <td>0.429706</td>\n",
       "      <td>0.692154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.844016</td>\n",
       "      <td>0.962410</td>\n",
       "      <td>0.423378</td>\n",
       "      <td>0.691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.886114</td>\n",
       "      <td>0.976637</td>\n",
       "      <td>0.425487</td>\n",
       "      <td>0.691774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.891047</td>\n",
       "      <td>0.978275</td>\n",
       "      <td>0.430823</td>\n",
       "      <td>0.693884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.892288</td>\n",
       "      <td>0.979090</td>\n",
       "      <td>0.431443</td>\n",
       "      <td>0.692147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.917727</td>\n",
       "      <td>0.985673</td>\n",
       "      <td>0.434173</td>\n",
       "      <td>0.690007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.923838</td>\n",
       "      <td>0.987681</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.696357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.924614</td>\n",
       "      <td>0.988658</td>\n",
       "      <td>0.435042</td>\n",
       "      <td>0.694399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.939474</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>0.433056</td>\n",
       "      <td>0.691986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.949277</td>\n",
       "      <td>0.993231</td>\n",
       "      <td>0.441122</td>\n",
       "      <td>0.697240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.947354</td>\n",
       "      <td>0.993734</td>\n",
       "      <td>0.441494</td>\n",
       "      <td>0.696429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.954706</td>\n",
       "      <td>0.994589</td>\n",
       "      <td>0.436282</td>\n",
       "      <td>0.692948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.963517</td>\n",
       "      <td>0.996257</td>\n",
       "      <td>0.443603</td>\n",
       "      <td>0.697136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.963145</td>\n",
       "      <td>0.996634</td>\n",
       "      <td>0.437275</td>\n",
       "      <td>0.696882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.965316</td>\n",
       "      <td>0.996437</td>\n",
       "      <td>0.431443</td>\n",
       "      <td>0.690011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.973134</td>\n",
       "      <td>0.997805</td>\n",
       "      <td>0.439757</td>\n",
       "      <td>0.697571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.972731</td>\n",
       "      <td>0.998204</td>\n",
       "      <td>0.428961</td>\n",
       "      <td>0.694988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.972979</td>\n",
       "      <td>0.997507</td>\n",
       "      <td>0.433428</td>\n",
       "      <td>0.692794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.980393</td>\n",
       "      <td>0.998688</td>\n",
       "      <td>0.442983</td>\n",
       "      <td>0.697960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.979649</td>\n",
       "      <td>0.999007</td>\n",
       "      <td>0.430947</td>\n",
       "      <td>0.695250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.772849</td>\n",
       "      <td>0.930310</td>\n",
       "      <td>0.424991</td>\n",
       "      <td>0.688255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.774338</td>\n",
       "      <td>0.931358</td>\n",
       "      <td>0.423129</td>\n",
       "      <td>0.689709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.768071</td>\n",
       "      <td>0.929736</td>\n",
       "      <td>0.422509</td>\n",
       "      <td>0.687680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.831761</td>\n",
       "      <td>0.956356</td>\n",
       "      <td>0.436407</td>\n",
       "      <td>0.689885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.834336</td>\n",
       "      <td>0.957939</td>\n",
       "      <td>0.429706</td>\n",
       "      <td>0.692543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.830862</td>\n",
       "      <td>0.957897</td>\n",
       "      <td>0.425363</td>\n",
       "      <td>0.689518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.973474</td>\n",
       "      <td>0.437027</td>\n",
       "      <td>0.690219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.882857</td>\n",
       "      <td>0.975692</td>\n",
       "      <td>0.433180</td>\n",
       "      <td>0.694877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.879506</td>\n",
       "      <td>0.975505</td>\n",
       "      <td>0.426728</td>\n",
       "      <td>0.691828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.911925</td>\n",
       "      <td>0.983817</td>\n",
       "      <td>0.434421</td>\n",
       "      <td>0.689186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.917292</td>\n",
       "      <td>0.986120</td>\n",
       "      <td>0.432064</td>\n",
       "      <td>0.695769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.915307</td>\n",
       "      <td>0.986260</td>\n",
       "      <td>0.432932</td>\n",
       "      <td>0.692711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.934975</td>\n",
       "      <td>0.990037</td>\n",
       "      <td>0.437896</td>\n",
       "      <td>0.691515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.942886</td>\n",
       "      <td>0.992121</td>\n",
       "      <td>0.432684</td>\n",
       "      <td>0.697035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.941739</td>\n",
       "      <td>0.992407</td>\n",
       "      <td>0.436531</td>\n",
       "      <td>0.694522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.951852</td>\n",
       "      <td>0.993703</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>0.690956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.960477</td>\n",
       "      <td>0.995573</td>\n",
       "      <td>0.436903</td>\n",
       "      <td>0.696366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.959298</td>\n",
       "      <td>0.995842</td>\n",
       "      <td>0.435662</td>\n",
       "      <td>0.695309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.963982</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.437275</td>\n",
       "      <td>0.689276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.971148</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.438392</td>\n",
       "      <td>0.696624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.970249</td>\n",
       "      <td>0.997707</td>\n",
       "      <td>0.430823</td>\n",
       "      <td>0.694805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.970900</td>\n",
       "      <td>0.997058</td>\n",
       "      <td>0.436034</td>\n",
       "      <td>0.689816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.978780</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>0.439757</td>\n",
       "      <td>0.697372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.976609</td>\n",
       "      <td>0.998696</td>\n",
       "      <td>0.430699</td>\n",
       "      <td>0.693919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  train_accuracy  \\\n",
       "0   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.780821   \n",
       "1   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.785692   \n",
       "2   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.781194   \n",
       "3   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.839517   \n",
       "4   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.846032   \n",
       "5   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.844016   \n",
       "6   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.886114   \n",
       "7   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.891047   \n",
       "8   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.892288   \n",
       "9   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.917727   \n",
       "10  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.923838   \n",
       "11  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.924614   \n",
       "12  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.939474   \n",
       "13  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.949277   \n",
       "14  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.947354   \n",
       "15  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.954706   \n",
       "16  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.963517   \n",
       "17  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.963145   \n",
       "18  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.965316   \n",
       "19  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.973134   \n",
       "20  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.972731   \n",
       "21  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.972979   \n",
       "22  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.980393   \n",
       "23  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.979649   \n",
       "24  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.772849   \n",
       "25  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.774338   \n",
       "26  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.768071   \n",
       "27  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.831761   \n",
       "28  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.834336   \n",
       "29  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.830862   \n",
       "30  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.876404   \n",
       "31  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.882857   \n",
       "32  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.879506   \n",
       "33  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.911925   \n",
       "34  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.917292   \n",
       "35  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.915307   \n",
       "36  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.934975   \n",
       "37  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.942886   \n",
       "38  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.941739   \n",
       "39  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.951852   \n",
       "40  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.960477   \n",
       "41  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.959298   \n",
       "42  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.963982   \n",
       "43  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.971148   \n",
       "44  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.970249   \n",
       "45  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.970900   \n",
       "46  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.978780   \n",
       "47  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.976609   \n",
       "\n",
       "    train_auc  test_accuracy  test_auc  \n",
       "0    0.935099       0.428465  0.689275  \n",
       "1    0.937528       0.424122  0.689317  \n",
       "2    0.935619       0.424618  0.691006  \n",
       "3    0.960353       0.428465  0.690851  \n",
       "4    0.963506       0.429706  0.692154  \n",
       "5    0.962410       0.423378  0.691500  \n",
       "6    0.976637       0.425487  0.691774  \n",
       "7    0.978275       0.430823  0.693884  \n",
       "8    0.979090       0.431443  0.692147  \n",
       "9    0.985673       0.434173  0.690007  \n",
       "10   0.987681       0.435538  0.696357  \n",
       "11   0.988658       0.435042  0.694399  \n",
       "12   0.991256       0.433056  0.691986  \n",
       "13   0.993231       0.441122  0.697240  \n",
       "14   0.993734       0.441494  0.696429  \n",
       "15   0.994589       0.436282  0.692948  \n",
       "16   0.996257       0.443603  0.697136  \n",
       "17   0.996634       0.437275  0.696882  \n",
       "18   0.996437       0.431443  0.690011  \n",
       "19   0.997805       0.439757  0.697571  \n",
       "20   0.998204       0.428961  0.694988  \n",
       "21   0.997507       0.433428  0.692794  \n",
       "22   0.998688       0.442983  0.697960  \n",
       "23   0.999007       0.430947  0.695250  \n",
       "24   0.930310       0.424991  0.688255  \n",
       "25   0.931358       0.423129  0.689709  \n",
       "26   0.929736       0.422509  0.687680  \n",
       "27   0.956356       0.436407  0.689885  \n",
       "28   0.957939       0.429706  0.692543  \n",
       "29   0.957897       0.425363  0.689518  \n",
       "30   0.973474       0.437027  0.690219  \n",
       "31   0.975692       0.433180  0.694877  \n",
       "32   0.975505       0.426728  0.691828  \n",
       "33   0.983817       0.434421  0.689186  \n",
       "34   0.986120       0.432064  0.695769  \n",
       "35   0.986260       0.432932  0.692711  \n",
       "36   0.990037       0.437896  0.691515  \n",
       "37   0.992121       0.432684  0.697035  \n",
       "38   0.992407       0.436531  0.694522  \n",
       "39   0.993703       0.435910  0.690956  \n",
       "40   0.995573       0.436903  0.696366  \n",
       "41   0.995842       0.435662  0.695309  \n",
       "42   0.995851       0.437275  0.689276  \n",
       "43   0.997359       0.438392  0.696624  \n",
       "44   0.997707       0.430823  0.694805  \n",
       "45   0.997058       0.436034  0.689816  \n",
       "46   0.998452       0.439757  0.697372  \n",
       "47   0.998696       0.430699  0.693919  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns=['params', 'train_accuracy','train_auc','test_accuracy', 'test_auc'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameter values and performance is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.963517</td>\n",
       "      <td>0.996257</td>\n",
       "      <td>0.443603</td>\n",
       "      <td>0.697136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  train_accuracy  \\\n",
       "16  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.963517   \n",
       "\n",
       "    train_auc  test_accuracy  test_auc  \n",
       "16   0.996257       0.443603  0.697136  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.test_accuracy == df.test_accuracy.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of this model (44%) is better than the default one used in notebook 03 (41%). Bit is lower than the neural network one (48%).\n",
    "\n",
    "We will show the confusion matrix and classification report for this model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1061,  394,  294,  226],\n",
       "       [ 673,  633,  427,  321],\n",
       "       [ 364,  416,  762,  524],\n",
       "       [ 201,  269,  375, 1119]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_cla, np.argmax(preds[df[df.test_accuracy == df.test_accuracy.max()].index[0]],axis=1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.46      0.54      0.50      1975\n",
      "     class 1       0.37      0.31      0.34      2054\n",
      "     class 2       0.41      0.37      0.39      2066\n",
      "     class 3       0.51      0.57      0.54      1964\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      8059\n",
      "   macro avg       0.44      0.45      0.44      8059\n",
      "weighted avg       0.44      0.44      0.44      8059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ['class 0', 'class 1', 'class 2', 'class 3']\n",
    "print(classification_report(y_test_cla, np.argmax(preds[df[df.test_accuracy == df.test_accuracy.max()].index[0]],axis=1), target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "df_cm = pd.DataFrame(cm, np.arange(4), np.arange(4))\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d') ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will train an xgboost model with the image features only :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.798970</td>\n",
       "      <td>0.943698</td>\n",
       "      <td>0.270381</td>\n",
       "      <td>0.524535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.809828</td>\n",
       "      <td>0.948359</td>\n",
       "      <td>0.274352</td>\n",
       "      <td>0.526770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.833499</td>\n",
       "      <td>0.959354</td>\n",
       "      <td>0.270877</td>\n",
       "      <td>0.526278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.855091</td>\n",
       "      <td>0.966502</td>\n",
       "      <td>0.271250</td>\n",
       "      <td>0.521581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.864956</td>\n",
       "      <td>0.970241</td>\n",
       "      <td>0.274848</td>\n",
       "      <td>0.526190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.891016</td>\n",
       "      <td>0.979511</td>\n",
       "      <td>0.268520</td>\n",
       "      <td>0.524357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.897220</td>\n",
       "      <td>0.980330</td>\n",
       "      <td>0.271374</td>\n",
       "      <td>0.523330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.908389</td>\n",
       "      <td>0.983760</td>\n",
       "      <td>0.279315</td>\n",
       "      <td>0.525920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.930911</td>\n",
       "      <td>0.990314</td>\n",
       "      <td>0.270133</td>\n",
       "      <td>0.526693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.931005</td>\n",
       "      <td>0.989191</td>\n",
       "      <td>0.269140</td>\n",
       "      <td>0.525261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.940653</td>\n",
       "      <td>0.991720</td>\n",
       "      <td>0.270009</td>\n",
       "      <td>0.527634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.958708</td>\n",
       "      <td>0.995732</td>\n",
       "      <td>0.273979</td>\n",
       "      <td>0.527545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.955823</td>\n",
       "      <td>0.994535</td>\n",
       "      <td>0.280184</td>\n",
       "      <td>0.527255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.961811</td>\n",
       "      <td>0.996033</td>\n",
       "      <td>0.272739</td>\n",
       "      <td>0.523371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.976112</td>\n",
       "      <td>0.998109</td>\n",
       "      <td>0.273979</td>\n",
       "      <td>0.527296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.970714</td>\n",
       "      <td>0.996872</td>\n",
       "      <td>0.276089</td>\n",
       "      <td>0.526526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.975430</td>\n",
       "      <td>0.997898</td>\n",
       "      <td>0.268271</td>\n",
       "      <td>0.521452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.986753</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.272863</td>\n",
       "      <td>0.527226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>0.998237</td>\n",
       "      <td>0.277330</td>\n",
       "      <td>0.524430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.985419</td>\n",
       "      <td>0.998988</td>\n",
       "      <td>0.275717</td>\n",
       "      <td>0.523534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.992182</td>\n",
       "      <td>0.999607</td>\n",
       "      <td>0.268520</td>\n",
       "      <td>0.525400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.998972</td>\n",
       "      <td>0.274352</td>\n",
       "      <td>0.528188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.990352</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>0.268271</td>\n",
       "      <td>0.524045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.996153</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.273111</td>\n",
       "      <td>0.525129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.796209</td>\n",
       "      <td>0.941478</td>\n",
       "      <td>0.275220</td>\n",
       "      <td>0.526817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.806695</td>\n",
       "      <td>0.946606</td>\n",
       "      <td>0.269264</td>\n",
       "      <td>0.528514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.830459</td>\n",
       "      <td>0.958081</td>\n",
       "      <td>0.268520</td>\n",
       "      <td>0.525985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.848762</td>\n",
       "      <td>0.964314</td>\n",
       "      <td>0.268147</td>\n",
       "      <td>0.522679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.859248</td>\n",
       "      <td>0.967690</td>\n",
       "      <td>0.280308</td>\n",
       "      <td>0.530705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.883012</td>\n",
       "      <td>0.977458</td>\n",
       "      <td>0.272614</td>\n",
       "      <td>0.526355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.893436</td>\n",
       "      <td>0.979256</td>\n",
       "      <td>0.275220</td>\n",
       "      <td>0.527200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.902060</td>\n",
       "      <td>0.981769</td>\n",
       "      <td>0.278446</td>\n",
       "      <td>0.534282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.926351</td>\n",
       "      <td>0.989108</td>\n",
       "      <td>0.271250</td>\n",
       "      <td>0.528857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.928523</td>\n",
       "      <td>0.988166</td>\n",
       "      <td>0.275220</td>\n",
       "      <td>0.527754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.933300</td>\n",
       "      <td>0.990168</td>\n",
       "      <td>0.280184</td>\n",
       "      <td>0.534027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.952845</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.274476</td>\n",
       "      <td>0.529088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.951014</td>\n",
       "      <td>0.993492</td>\n",
       "      <td>0.272987</td>\n",
       "      <td>0.527473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.954272</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.276833</td>\n",
       "      <td>0.532919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.971459</td>\n",
       "      <td>0.997654</td>\n",
       "      <td>0.270381</td>\n",
       "      <td>0.528550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.967395</td>\n",
       "      <td>0.996287</td>\n",
       "      <td>0.273607</td>\n",
       "      <td>0.526227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.970993</td>\n",
       "      <td>0.997226</td>\n",
       "      <td>0.272614</td>\n",
       "      <td>0.526973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.998959</td>\n",
       "      <td>0.274476</td>\n",
       "      <td>0.528731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.997919</td>\n",
       "      <td>0.275717</td>\n",
       "      <td>0.526090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.981510</td>\n",
       "      <td>0.998523</td>\n",
       "      <td>0.278943</td>\n",
       "      <td>0.531752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.990817</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>0.276089</td>\n",
       "      <td>0.527409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.985016</td>\n",
       "      <td>0.998814</td>\n",
       "      <td>0.273855</td>\n",
       "      <td>0.527290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.987312</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.281300</td>\n",
       "      <td>0.532873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>0.274352</td>\n",
       "      <td>0.525907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  train_accuracy  \\\n",
       "0   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.798970   \n",
       "1   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.809828   \n",
       "2   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.833499   \n",
       "3   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.855091   \n",
       "4   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.864956   \n",
       "5   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.891016   \n",
       "6   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.897220   \n",
       "7   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.908389   \n",
       "8   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.930911   \n",
       "9   {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.931005   \n",
       "10  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.940653   \n",
       "11  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.958708   \n",
       "12  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.955823   \n",
       "13  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.961811   \n",
       "14  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.976112   \n",
       "15  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.970714   \n",
       "16  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.975430   \n",
       "17  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.986753   \n",
       "18  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.979804   \n",
       "19  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.985419   \n",
       "20  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.992182   \n",
       "21  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.986567   \n",
       "22  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.990352   \n",
       "23  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.996153   \n",
       "24  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.796209   \n",
       "25  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.806695   \n",
       "26  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.830459   \n",
       "27  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.848762   \n",
       "28  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.859248   \n",
       "29  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.883012   \n",
       "30  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.893436   \n",
       "31  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.902060   \n",
       "32  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.926351   \n",
       "33  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.928523   \n",
       "34  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.933300   \n",
       "35  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.952845   \n",
       "36  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.951014   \n",
       "37  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.954272   \n",
       "38  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.971459   \n",
       "39  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.967395   \n",
       "40  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.970993   \n",
       "41  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.983713   \n",
       "42  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.977974   \n",
       "43  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.981510   \n",
       "44  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.990817   \n",
       "45  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.985016   \n",
       "46  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.987312   \n",
       "47  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.995129   \n",
       "\n",
       "    train_auc  test_accuracy  test_auc  \n",
       "0    0.943698       0.270381  0.524535  \n",
       "1    0.948359       0.274352  0.526770  \n",
       "2    0.959354       0.270877  0.526278  \n",
       "3    0.966502       0.271250  0.521581  \n",
       "4    0.970241       0.274848  0.526190  \n",
       "5    0.979511       0.268520  0.524357  \n",
       "6    0.980330       0.271374  0.523330  \n",
       "7    0.983760       0.279315  0.525920  \n",
       "8    0.990314       0.270133  0.526693  \n",
       "9    0.989191       0.269140  0.525261  \n",
       "10   0.991720       0.270009  0.527634  \n",
       "11   0.995732       0.273979  0.527545  \n",
       "12   0.994535       0.280184  0.527255  \n",
       "13   0.996033       0.272739  0.523371  \n",
       "14   0.998109       0.273979  0.527296  \n",
       "15   0.996872       0.276089  0.526526  \n",
       "16   0.997898       0.268271  0.521452  \n",
       "17   0.999216       0.272863  0.527226  \n",
       "18   0.998237       0.277330  0.524430  \n",
       "19   0.998988       0.275717  0.523534  \n",
       "20   0.999607       0.268520  0.525400  \n",
       "21   0.998972       0.274352  0.528188  \n",
       "22   0.999457       0.268271  0.524045  \n",
       "23   0.999781       0.273111  0.525129  \n",
       "24   0.941478       0.275220  0.526817  \n",
       "25   0.946606       0.269264  0.528514  \n",
       "26   0.958081       0.268520  0.525985  \n",
       "27   0.964314       0.268147  0.522679  \n",
       "28   0.967690       0.280308  0.530705  \n",
       "29   0.977458       0.272614  0.526355  \n",
       "30   0.979256       0.275220  0.527200  \n",
       "31   0.981769       0.278446  0.534282  \n",
       "32   0.989108       0.271250  0.528857  \n",
       "33   0.988166       0.275220  0.527754  \n",
       "34   0.990168       0.280184  0.534027  \n",
       "35   0.994851       0.274476  0.529088  \n",
       "36   0.993492       0.272987  0.527473  \n",
       "37   0.994650       0.276833  0.532919  \n",
       "38   0.997654       0.270381  0.528550  \n",
       "39   0.996287       0.273607  0.526227  \n",
       "40   0.997226       0.272614  0.526973  \n",
       "41   0.998959       0.274476  0.528731  \n",
       "42   0.997919       0.275717  0.526090  \n",
       "43   0.998523       0.278943  0.531752  \n",
       "44   0.999496       0.276089  0.527409  \n",
       "45   0.998814       0.273855  0.527290  \n",
       "46   0.999207       0.281300  0.532873  \n",
       "47   0.999742       0.274352  0.525907  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(data=image_df_train, label=y_train_cla)\n",
    "dtest = xgb.DMatrix(data=image_df_test)\n",
    "results_img, preds_img =  grid_xgb(params)\n",
    "df_img = pd.DataFrame(results_img, columns=['params', 'train_accuracy','train_auc','test_accuracy', 'test_auc'])\n",
    "df_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img.to_pickle(\"df_img.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...</td>\n",
       "      <td>0.987312</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>0.532873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  train_accuracy  \\\n",
       "46  {'gamma': 0, 'lambda': 1, 'learning_rate': 0.0...        0.987312   \n",
       "\n",
       "    train_auc  test_accuracy  test_auc  \n",
       "46   0.999207         0.2813  0.532873  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_img[df_img.test_accuracy == df_img.test_accuracy.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the performance of the best model (28%) is about the same as baseline (25%).\n",
    "\n",
    "The image features does not contains helpfull information to classify our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
